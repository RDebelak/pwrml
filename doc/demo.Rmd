---
title: "Demo"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Demo}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r include=FALSE}
knitr::opts_chunk$set(eval=TRUE)
```

```{r message=FALSE}
library(pwrml)
library(mirt)
library(dplyr)

# To install the most recent mirt version (currently, some matrices may otherwise not be calculated correctly):
# library(devtools)
# install_github('philchalmers/mirt')
```


# Introduction

This vignette introduces the implementation of a power analysis for the Wald, LR, score and gradient test for linear hypothesis. It uses some IRT examples and treats basic as well as additional features of the package. It is directed towards beginner to intermediate level R users. Previous experience with the mirt package may be helpful. In the following we will cover the three-step workflow in detail:

* Setup Hypotheses (setup_hypothesis)
* Calculate Noncentrality Parameters (calculate_ncps)
* Calculate Power or Sample Size (power, ssize)

As additional features, we cover:

* Generate artificial datasets
* Performing hypothesis tests
* Estimating the time needed


# Workflow example

We want to know the power and required sample size for a test of the Rasch vs 2PL model. We use the LSAT 7 Dataset from the mirt package.

As a first step, we load the dataset and fit a 2PL model.

```{r}
dat <- expand.table(LSAT7)
mirtfit <- mirt(dat,1,verbose = FALSE)
```

The 2PL parameters are then used as parameters for the alternative hypothesis in our hypothesis definition.
```{r}
hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = mirtfit)
```

We can now calculate the noncentrality parameters.
```{r}
ncps <- calculate_ncps(hyp=hyp)
```

From the noncentrality parameters, we can estimate the power or required sample size.
```{r}
power(hyp=hyp,ncp=ncps,alpha=.05,ssize=500)
ssize(hyp=hyp,ncp=ncps,alpha=.05,power=.80)
```


# Functions in detail

We will present all included functions and their arguments in more detail.

## Setup Hypotheses (setup_hypothesis)

We can either use a fitted mirt model or specify alternative parameters directly. An example of the letter would be:

```{r}
altpars <- list(
        a = rlnorm(5,sdlog = .4),
        d = rnorm(5)
        )
altpars
hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = altpars)

```

The following alternative hypotheses are currently implemented.

* Rasch against 2PL
* DIF in 2PL

The Rasch against 2PL hypothesis is presented above. The procedure for the DIF in 2PL hypothesis is analogous, yet is a bit more complicated since we need to define different groups:

```{r}
group1 = group2 <- list(
        a = rlnorm(5,sdlog = .2),
        d = rnorm(5)
        )

group2$a[1] = (group2$a[1])^2
group2$d[1] = group2$d[1] + .5

altpars <- list(group1,group2)

altpars

hyp <- setup_hypothesis(type = "DIF2PL", altpars = altpars)

```

To implement custom hypotheses, please refer to the respective vignette. Note that for both hypothesis types, we do not have to provide the parameters under the null hypothesis here, because they are implicitly defined by the hypotheses. The setup_hypothesis function, however, also takes a nullpars argument for cases in which the parmaters under the null hypothesis are not identified by the parameters under the alternative.


## Calculate Noncentrality Parameters (calculate_ncps)

The calculation of noncentrality parameters is straightforward. 
```{r}
ncps <- calculate_ncps(hyp=hyp)
```

To use the sampling-based parameters, one may use sampling=TRUE. The sample size of the sampling-based approach and the approximation of the Fisher expected matrix may be tweaked or left at their default values.

```{r}
ncps <- calculate_ncps(hyp=hyp,sampling=TRUE,sampling.npers = 10^4,approx.npers=10^4)
```


## Calculate Power or Sample Size (power, ssize)

The functions to calculate power and sample size are straightforward. One may use them to plot a power curve.
```{r}
n = seq(100,2000)
pow = power(hyp=hyp,ncp=ncps["Gradient"],alpha=.05,ssize=n)
plot(n,pow)
```



# Additional Features

We will take a look at some additional features.

## Generate artificial datasets

The hypothesis object can also be used to generate data according to the parameters of the alternative hypothesis. Note that setup.data also allows for non-normal person distributions, e.g. uniform or skewed-normal distributions.
```{r}
altpars <- list(
        a = rlnorm(5,sdlog = .4),
        d = rnorm(5)
        )

hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = altpars)

data <- setup.data(hyp=hyp,n=500)
```


## Performing Hypothesis Tests

One can also perform hypothesis tests on observed data. This is done in two steps, model fitting (mml.fit) and calculation of the statitics (stat_obs). To fit both an unrestricted and restricted model in one go, we specify the data and the hypothesis.

```{r}
fitted <- mml.fit(data = data,hyp = hyp)
```

One may also use an approximation of the Fisher expected matrix, e.g. for larger item sets.
```{r}
fitted <- mml.fit(data = data,hyp = hyp,infmat.unres = "ApproxFisher",infmat.res="ApproxFisher",approx.npers = 10^4)
```

From the results, we can calculate the observed statistics and p-values.

```{r}
stats_obs <- stat_obs(fitted)
stats_obs
pvals <- pchisq(stats_obs,df=nrow(hyp$resmod$Amat),ncp=0,lower.tail=FALSE)
pvals
```


## Estimating the time needed for the analytical approach

We can calculate the approximate time needed to calculate the analytical noncentrality parameters using a larger numbers of items.

```{r}
altpars <- list(
        a = rlnorm(5,sdlog = .4),
        d = rnorm(5)
        )

hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = altpars)

calctime(hyp,n.items=7)
```

Measuring the actual time for comparison:

```{r}
altpars <- list(
        a = rlnorm(7,sdlog = .4),
        d = rnorm(7)
        )

hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = altpars)

calctime(hyp,n.items=7)

```

The time measuring method is currently not very accurate. As a result from my test runs, I suggest to expect +80% as a worst case scenario.

